# model-zoo

1. Pytorch code of GRU "Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation" [code](https://github.com/wuqianliangsresearch/model-zoo/blob/master/seq2seq_mt/train_without_attention.py)
2. Pytorch code of soft attention "NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE" [code](https://github.com/wuqianliangsresearch/model-zoo/blob/master/seq2seq_mt/train_with_attention.py)
3. Pytorch code of soft attention "Effective Approaches to Attention-based Neural Machine Translation" [global attention](https://github.com/wuqianliangsresearch/model-zoo/blob/master/seq2seq_mt/train_with_global_attention.py) [local attention](https://github.com/wuqianliangsresearch/model-zoo/blob/master/seq2seq_mt/train_with_local_attention.py)  [data page](https://nlp.stanford.edu/projects/nmt/) 
4. Pytorch code of "Hierarchical Attention Networks for Document Classification" [code](https://github.com/wuqianliangsresearch/model-zoo/blob/master/text_class/train_with_Hierarchical.py)
5. Pytorch code of "Attention Is All You Need" [code](https://github.com/wuqianliangsresearch/model-zoo/tree/master/seq2seq_mt/self_attention_transformer) . Also reference from [others](https://github.com/jadore801120/attention-is-all-you-need-pytorch)
6. FAIR VERSION Pytorch code of "Convolutional Sequence to Sequence Learning" [code](https://github.com/facebookresearch/fairseq)
7. ELMo
8. GPT
9. Bert
